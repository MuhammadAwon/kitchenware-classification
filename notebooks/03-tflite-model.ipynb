{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99c3c4",
   "metadata": {},
   "source": [
    "# TensorFlow Lite model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba337b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479abe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = tf.keras.models.load_model('../models/efficientnetb0_14_0.962.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094d127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of unseen images\n",
    "eval_imgs_dir = '../datasets/kitchenware-dataset/eval-images'\n",
    "\n",
    "# Get the images filepaths\n",
    "custom_imgs = [eval_imgs_dir + '/' + img_path for img_path in os.listdir(eval_imgs_dir)]\n",
    "\n",
    "# Get the cup image\n",
    "cup_img = custom_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699ebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow library to load image\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e99c61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[110.,  80.,  69.],\n",
       "         [108.,  78.,  67.],\n",
       "         [115.,  85.,  74.],\n",
       "         ...,\n",
       "         [ 94.,  70.,  60.],\n",
       "         [ 94.,  70.,  60.],\n",
       "         [ 94.,  70.,  60.]],\n",
       "\n",
       "        [[114.,  85.,  71.],\n",
       "         [115.,  86.,  72.],\n",
       "         [116.,  87.,  73.],\n",
       "         ...,\n",
       "         [ 84.,  59.,  52.],\n",
       "         [ 91.,  67.,  57.],\n",
       "         [ 91.,  67.,  55.]],\n",
       "\n",
       "        [[117.,  88.,  72.],\n",
       "         [110.,  81.,  67.],\n",
       "         [120.,  91.,  77.],\n",
       "         ...,\n",
       "         [ 94.,  69.,  62.],\n",
       "         [ 95.,  71.,  61.],\n",
       "         [ 93.,  69.,  57.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 19.,   7.,   7.],\n",
       "         [ 17.,   6.,   4.],\n",
       "         [ 18.,   7.,   5.],\n",
       "         ...,\n",
       "         [ 68.,  46.,  33.],\n",
       "         [ 68.,  46.,  35.],\n",
       "         [ 70.,  48.,  37.]],\n",
       "\n",
       "        [[ 19.,  10.,   5.],\n",
       "         [ 17.,   8.,   3.],\n",
       "         [ 16.,   7.,   2.],\n",
       "         ...,\n",
       "         [ 67.,  43.,  31.],\n",
       "         [ 71.,  47.,  35.],\n",
       "         [ 67.,  43.,  33.]],\n",
       "\n",
       "        [[ 18.,   7.,   5.],\n",
       "         [ 22.,  11.,   9.],\n",
       "         [ 21.,  10.,   8.],\n",
       "         ...,\n",
       "         [ 73.,  48.,  41.],\n",
       "         [ 68.,  43.,  36.],\n",
       "         [ 69.,  45.,  35.]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image\n",
    "img = load_img(cup_img, target_size=(256, 256))\n",
    "\n",
    "# Convert image to numpy array and add batch dimension\n",
    "x = np.array(img, dtype='float32') # must be float32 for tflite model\n",
    "X = np.expand_dims(x, axis=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ddf7b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.8942554e-01, 7.5928824e-07, 1.0567816e-02, 5.2624791e-06,\n",
       "       4.8197681e-08, 4.8940933e-07], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make model prediction on the cup image\n",
    "preds = model.predict(X)[0]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e58a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup': 0.98942554,\n",
       " 'fork': 7.5928824e-07,\n",
       " 'glass': 0.010567816,\n",
       " 'knife': 5.262479e-06,\n",
       " 'plate': 4.819768e-08,\n",
       " 'spoon': 4.8940933e-07}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of classes the model was trained to predict\n",
    "classes = ['cup', 'fork', 'glass', 'knife', 'plate', 'spoon']\n",
    "\n",
    "# Check the prediction scores\n",
    "dict(zip(classes, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960f882",
   "metadata": {},
   "source": [
    "## Convert keras model to tf-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ebf5bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\awon\\AppData\\Local\\Temp\\tmpcgcg6kyc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\awon\\AppData\\Local\\Temp\\tmpcgcg6kyc\\assets\n"
     ]
    }
   ],
   "source": [
    "# Initialize tf-lite converter for keras model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# Make model conversion\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model in tflite format\n",
    "with open('../models/kitchenware-model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460fe075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 35M\n",
      "-rw-r--r-- 1 awon 197121 19M Dec 15 06:52 efficientnetb0_14_0.962.h5\n",
      "-rw-r--r-- 1 awon 197121 17M Dec 16 15:14 kitchenware-model.tflite\n"
     ]
    }
   ],
   "source": [
    "# Check the saved models and their sizes\n",
    "!ls -lh ../models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23df5fb",
   "metadata": {},
   "source": [
    "## Make predictions with tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf8d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow lite module\n",
    "import tensorflow.lite as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacdc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model using Interpreter class\n",
    "interpreter = tflite.Interpreter(model_path='../models/kitchenware-model.tflite')\n",
    "# Load the weights from the model to memory\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get the input index from interpreter\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "# Get the output index from interpreter\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6687bcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.8942566e-01, 7.5928978e-07, 1.0567832e-02, 5.2624650e-06,\n",
       "       4.8197595e-08, 4.8940842e-07], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the value of the input tensor using input_index to the image X\n",
    "interpreter.set_tensor(input_index, X)\n",
    "# Invoke the interpreter\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the value of the output tensor using output_index to make prediction\n",
    "tflite_preds = interpreter.get_tensor(output_index)[0]\n",
    "tflite_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fcfb09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup': 0.98942554,\n",
       " 'fork': 7.5928824e-07,\n",
       " 'glass': 0.010567816,\n",
       " 'knife': 5.262479e-06,\n",
       " 'plate': 4.819768e-08,\n",
       " 'spoon': 4.8940933e-07}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the prediction scores\n",
    "dict(zip(classes, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a30352",
   "metadata": {},
   "source": [
    "## Removing TF dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e650f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflite_runtime.interpreter as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d796c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize interpreter\n",
    "interpreter = tflite.Interpreter(model_path='../models/kitchenware-model.tflite')\n",
    "# Allocate memory\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input index\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "# Get output index\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55060b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "from PIL import Image\n",
    "from PIL.Image import Resampling\n",
    "\n",
    "\n",
    "def preprocess_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, resample=Resampling.NEAREST)\n",
    "    x = np.array(img, dtype='float32')\n",
    "    X = np.expand_dims(x, axis=0)\n",
    "    return X\n",
    "\n",
    "def image_from_url(url, target_size=(256, 256)):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return preprocess_image(img, target_size)\n",
    "\n",
    "def image_from_path(path, target_size=(256, 256)):\n",
    "    with Image.open(path) as img:\n",
    "        return preprocess_image(img, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15059e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From url\n",
    "url = 'https://static-01.daraz.pk/p/1dec6d4a0810d17bd9f1d835f192d922.jpg'\n",
    "\n",
    "# Create X matrix from image url\n",
    "X_url = image_from_url(url, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cc68112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the images filepaths\n",
    "custom_imgs = ['../datasets/kitchenware-dataset/eval-images' + '/' + img_path for img_path in os.listdir('../datasets/kitchenware-dataset/eval-images')]\n",
    "# Get the cup image\n",
    "img_path = custom_imgs[0]\n",
    "\n",
    "# Create X matrix from path url\n",
    "X = image_from_path(img_path, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c79ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup': 0.98942566,\n",
       " 'fork': 7.592926e-07,\n",
       " 'glass': 0.010567902,\n",
       " 'knife': 5.2625e-06,\n",
       " 'plate': 4.8197872e-08,\n",
       " 'spoon': 4.8941126e-07}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction on cup image from path\n",
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "tflite_runtime_preds = interpreter.get_tensor(output_index)[0]\n",
    "\n",
    "# List of classes\n",
    "classes = ['cup', 'fork', 'glass', 'knife', 'plate', 'spoon']\n",
    "\n",
    "# Check the prediction scores\n",
    "dict(zip(classes, tflite_runtime_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e45de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cup': 1.0,\n",
       " 'fork': 2.8106922e-10,\n",
       " 'glass': 2.9442784e-09,\n",
       " 'knife': 3.0271075e-10,\n",
       " 'plate': 6.8399513e-12,\n",
       " 'spoon': 8.5472615e-11}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction on cup image from url\n",
    "interpreter.set_tensor(input_index, X_url)\n",
    "interpreter.invoke()\n",
    "tflite_runtime_preds = interpreter.get_tensor(output_index)[0]\n",
    "\n",
    "# List of classes\n",
    "classes = ['cup', 'fork', 'glass', 'knife', 'plate', 'spoon']\n",
    "\n",
    "# Check the prediction scores\n",
    "dict(zip(classes, tflite_runtime_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d8e838d7ea4e7b4d5ef759a0092488531bf52cbbeb36b3ebbbb137b54254a517"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
